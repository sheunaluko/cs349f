{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CloudEx Algo Main Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path\n",
    "\n",
    "new_paths = ['/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/root/CloudExchange', '/root/']\n",
    "for p in new_paths : \n",
    "    sys.path.append(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import redis\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "# CloudEx imports.\n",
    "import cloud_ex\n",
    "\n",
    "# Import AlgorithmicTrader helper class.\n",
    "from algorithmic_trader_shay import AlgorithmicTrader\n",
    "from algorithmic_trader_shay import summarize_historical_trades_df\n",
    "\n",
    "# Start Redis and its Python API.\n",
    "os.system(\"redis-server --daemonize yes\")\n",
    "time.sleep(1)\n",
    "\n",
    "# Get CloudEX and VM-specific config. \n",
    "# NOTE: gateway_ip will be null when the exchange is not online \n",
    "def get_vm_config():\n",
    "    with open(\"/root/vm_config.json\", \"r\") as read_file:\n",
    "        config = json.load(read_file)\n",
    "    return config\n",
    "\n",
    "config = get_vm_config()\n",
    "\n",
    "\n",
    "# utilities\n",
    "ORDER_FIELDS_LIST = [\n",
    "    'Symbol', 'OrderID', 'CancelID', 'ClientID', 'OrderType', 'OrderAction',\n",
    "    'SubmitTimestamp', 'GatewayTimestamp', 'EnqueueTimestamp',\n",
    "    'DequeueTimestamp', 'OrderSerialNum', 'LimitPrice', 'ResultType','NumShares'\n",
    "]\n",
    "\n",
    "TRADE_FIELDS_LIST = [\n",
    "    \"Symbol\", \"BuyerSerialNum\", \"SellerSerialNum\", \"BuyerOrderID\",\n",
    "    \"SellerOrderID\", \"BuyerClientID\", \"SellerClientID\", \"ExecPrice\",\n",
    "    \"CashTraded\", \"SharesTraded\", \"CreationTimestamp\", \"ReleaseTimestamp\",\n",
    "    \"TradeSerialNum\"\n",
    "]\n",
    "\n",
    "'''\n",
    "Takes in a cloud_ex.VectorOrder with serialized orders and returns a DataFrame\n",
    "'''\n",
    "def OrderDF(order_vec):\n",
    "    if not len(order_vec):\n",
    "        return pd.DataFrame(columns=ORDER_FIELDS_LIST)\n",
    "    df = pd.DataFrame(order_vec).applymap(lambda x:x.SerializeOrder())[0].str.split('|', expand=True)\n",
    "    df.columns = ORDER_FIELDS_LIST\n",
    "    for label in ['SubmitTimestamp', 'GatewayTimestamp', 'EnqueueTimestamp',\n",
    "                  'DequeueTimestamp', 'OrderSerialNum', 'LimitPrice','NumShares']:\n",
    "        df.loc[:, label] = pd.to_numeric(df[label], errors='coerce')\n",
    "    return df\n",
    "\n",
    "'''\n",
    "Takes in a cloud_ex.VectorOrder with serialized trades and returns a DataFrame\n",
    "'''\n",
    "def TradeDF(trade_vec):\n",
    "    if not len(trade_vec):\n",
    "        return pd.DataFrame(columns=TRADE_FIELDS_LIST)\n",
    "    df = pd.DataFrame(trade_vec).applymap(lambda x:x.SerializeTrade())[0].str.split('|', expand=True)\n",
    "    df.columns = TRADE_FIELDS_LIST\n",
    "    for label in [\"ExecPrice\", \"CashTraded\", \"SharesTraded\",\n",
    "                  \"CreationTimestamp\", \"ReleaseTimestamp\", \"TradeSerialNum\"]:\n",
    "        df.loc[:, label] = pd.to_numeric(df[label], errors='coerce')\n",
    "    return df\n",
    "\n",
    "'''\n",
    "Takes in a cloud_ex.MapStringOrder mapping Order ID strings to outstanding the coorresponding orders, \n",
    "and returns a DataFrame\n",
    "'''\n",
    "def OutstandingOrderDF(outstanding_orders):\n",
    "    if not len(outstanding_orders):\n",
    "        return pd.DataFrame(columns=ORDER_FIELDS_LIST)\n",
    "    df = (pd.DataFrame(outstanding_orders.items())[1]).apply(lambda x:x.SerializeOrder()).str.split('|', expand=True)\n",
    "    df.columns = ORDER_FIELDS_LIST\n",
    "    for label in ['SubmitTimestamp', 'GatewayTimestamp', 'EnqueueTimestamp',\n",
    "                  'DequeueTimestamp', 'OrderSerialNum', 'LimitPrice','NumShares']:\n",
    "        df.loc[:, label] = pd.to_numeric(df[label], errors='coerce')\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib \n",
    "import sys \n",
    "#importlib.reload(sys.modules['mean_reversion_shay'])\n",
    "def reload(r) : \n",
    "    importlib.reload(sys.modules[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import strategies_shay   \n",
    "import threading\n",
    "import utilities as u \n",
    "default_symbols = ['AA', 'AB', 'AC', 'AD', 'AE', 'AF', 'AG', 'AH', 'AI', 'AJ', 'AK', 'AL', 'AM', 'AN', 'AO', 'AP', 'AQ', 'AR', 'AS', 'AT', 'AU', 'AV', 'AW', 'AX', 'AY', 'AZ', 'BA', 'BB', 'BC', 'BD', 'BE', 'BF', 'BG', 'BH', 'BI', 'BJ', 'BK', 'BL', 'BM', 'BN', 'BO', 'BP', 'BQ', 'BR', 'BS', 'BT', 'BU', 'BV', 'BW', 'BX', 'BY', 'BZ', 'CA', 'CB', 'CC', 'CD', 'CE', 'CF', 'CG', 'CH', 'CI', 'CJ', 'CK', 'CL', 'CM', 'CN', 'CO', 'CP', 'CQ', 'CR', 'CS', 'CT', 'CU', 'CV', 'CW', 'CX', 'CY', 'CZ', 'DA', 'DB', 'DC', 'DD', 'DE', 'DF', 'DG', 'DH', 'DI', 'DJ', 'DK', 'DL', 'DM', 'DN', 'DO', 'DP', 'DQ', 'DR', 'DS', 'DT', 'DU', 'DV']\n",
    "default_top_symbols = ['DV', 'CQ', 'DN', 'CL', 'CT', 'BF', 'CW', 'AW', 'DS', 'CS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the trader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrader() : \n",
    "    global trader\n",
    "    if trader : \n",
    "        u.debug(\"Returning saved trader\")\n",
    "        return trader\n",
    "\n",
    "    # Get relevant fields from VM-specific config. Token is yours only, so don't make it public.\n",
    "    gateway_ip = config[\"gateway_ip\"]\n",
    "    client_id = config[\"client_id\"]\n",
    "    client_token = config[\"client_token\"]\n",
    "\n",
    "    # Clear any existing data locally.\n",
    "    redis_api = redis.Redis()\n",
    "    redis_api.flushall();\n",
    "\n",
    "    # Create CloudEx base trader object.\n",
    "    trader = cloud_ex.Trader(gateway_ip, client_id, client_token)\n",
    "    return trader \n",
    "\n",
    "def getSymbols() : \n",
    "    trader = getTrader() \n",
    "    return trader.GetSymbols()\n",
    "\n",
    "\n",
    "def getPortfolio(): \n",
    "    portfolio_mat = cloud_ex.MapStringInt()\n",
    "    trader.GetPortfolioMatrix(portfolio_mat)\n",
    "    return portfolio_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = getTrader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['gateway_ip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Todos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting symbols to trade on based on aggregate volume over last n seconds  \n",
    "\n",
    "We need to figure out which symbols to trade on prior to the initiation of trading. It seems natural to rank them by some metric and then take the top N of them, for example volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def periodic_trading_decision(signal_y, timestep_lag = 10): \n",
    "    \"\"\"\n",
    "    Trade periodic signals by finding inflection points of price derivative over time.\n",
    "    \"\"\"\n",
    "    buys, sells = [], []    \n",
    "    dydx = np.diff(y)/np.diff(x)\n",
    "    dydx = np.insert(dydx, 0, 0.0, axis=0)\n",
    "    \n",
    "    for idx in range(timestep_lag, len(signal_y)):\n",
    "        sign_dy_current = math.copysign(1, dydx[idx])\n",
    "        sign_dy_prev = math.copysign(1, dydx[idx - 1])\n",
    "        \n",
    "        if sign_dy_current > sign_dy_prev:\n",
    "            buys.append((idx, signal_y[idx]))\n",
    "        elif sign_dy_current < sign_dy_prev:\n",
    "            sells.append((idx, signal_y[idx]))\n",
    "        else:\n",
    "            None\n",
    "\n",
    "    return buys, sells\n",
    "\n",
    "## (1) Define signal - clean (unnoised) periodic signal\n",
    "time_steps = 1000\n",
    "angular_frequency = 2 * np.pi * (5/time_steps) # 2 pi f -  5 periods over time_steps \n",
    "x = np.arange(time_steps)\n",
    "y = 5 * np.sin(angular_frequency * x) + 100 #  A sin(\\omega t) + \\delta\n",
    "\n",
    "## (2) Get trading decisions and plot\n",
    "buys, sells = periodic_trading_decision(y)\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.scatter([buys[idx][0] for idx in range(len(buys))],\n",
    "            [buys[idx][1] for idx in range(len(buys))], s=150,color='g', zorder=2)\n",
    "plt.scatter([sells[idx][0] for idx in range(len(sells))],\n",
    "            [sells[idx][1] for idx in range(len(sells))], s=150,color='r', zorder=2)\n",
    "\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_trading_decision_noised(signal_y, timestep_lag = 20, ma_length = 25): \n",
    "    \"\"\"\n",
    "    Trade periodic signals by finding inflection points of price derivative over time.\n",
    "    \"\"\"\n",
    "    buys, sells = [], []\n",
    "    dydx = np.diff(y)/np.diff(x)\n",
    "    dydx = np.insert(dydx, 0, 0.0, axis=0)\n",
    "    \n",
    "    for idx in range(timestep_lag, len(signal_y) - timestep_lag):\n",
    "        sign_dy_current = math.copysign(1, np.mean(dydx[(idx - ma_length):idx]))\n",
    "        sign_dy_prev = math.copysign(1, np.mean(dydx[(idx - 2*ma_length):(idx - ma_length)]))\n",
    "        \n",
    "        if sign_dy_current > sign_dy_prev:\n",
    "            buys.append((idx, signal_y[idx]))\n",
    "        elif sign_dy_current < sign_dy_prev:\n",
    "            sells.append((idx, signal_y[idx]))\n",
    "        else:\n",
    "            None\n",
    "\n",
    "    return buys, sells\n",
    "\n",
    "def smooth(y, box_pts = 10):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "## Define signal - Add standard normal noise (~Gaussian(0,1)) to the periodic signal\n",
    "time_steps = 1000\n",
    "angular_frequency = 2 * np.pi * (5/time_steps) # 2 pi f -  5 periods over time_steps \n",
    "x = np.arange(time_steps)\n",
    "y = 10 * np.sin(angular_frequency * x) + 100 + np.random.normal(0, 1, time_steps) #  A sin(\\omega t) + \\delta + \\gamma\n",
    "y_smooth = smooth(y, box_pts = 10)\n",
    "\n",
    "## Get trading decisions and plot\n",
    "buys, sells = periodic_trading_decision_noised(y_smooth)\n",
    "plt.plot(x[10:-10], y_smooth[10:-10])\n",
    "\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buys, sells = periodic_trading_decision_noised(x, y_smooth)\n",
    "plt.plot(x[10:-10], y_smooth[10:-10])\n",
    "\n",
    "plt.scatter([buys[idx][0] for idx in range(len(buys))],\n",
    "            [buys[idx][1] for idx in range(len(buys))], s=150,color='g', zorder=2)\n",
    "plt.scatter([sells[idx][0] for idx in range(len(sells))],\n",
    "            [sells[idx][1] for idx in range(len(sells))], s=150,color='r', zorder=2)\n",
    "\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def aggregate_volume(symbol, seconds_in_past) : \n",
    "    \"\"\"\n",
    "    Gets the most recent 'seconds_in_past' historical data for the symbol and compute the total \n",
    "    'CashTraded' \n",
    "    \"\"\"\n",
    "    u.debug(\"Getting aggregate volume for {}\".format(symbol))\n",
    "    end_time_ms = int(time.time()*1e3)\n",
    "    start_time_ms = end_time_ms - int(seconds_in_past*1e3)\n",
    "    symbol_trades_vec = cloud_ex.VectorTrade()  \n",
    "    cloud_ex.MarketDataAPI.PullTrades(config['project_id'], config['bigtable_id'], \n",
    "                                          config['table_name'], symbol, start_time_ms, \n",
    "                                          end_time_ms, symbol_trades_vec)\n",
    "    sym_df = TradeDF(symbol_trades_vec)\n",
    "    #print(sym_df)\n",
    "    print(\"Returning volume for symbol:\" + symbol)\n",
    "    return np.sum(sym_df['CashTraded'])    \n",
    "\n",
    "def periodicity_metric(symbol, seconds_in_past, normalize_with_dc = True): \n",
    "    \"\"\"\n",
    "    Find symbols with high degrees of periodicity.\n",
    "    \"\"\"\n",
    "    u.debug(\"Getting periodicity of {}\".format(symbol))\n",
    "    end_time_ms = int(time.time()*1e3)\n",
    "    start_time_ms = end_time_ms - int(seconds_in_past*1e3)\n",
    "    symbol_trades_vec = cloud_ex.VectorTrade()  \n",
    "    cloud_ex.MarketDataAPI.PullTrades(config['project_id'], config['bigtable_id'], \n",
    "                                          config['table_name'], symbol, start_time_ms, \n",
    "                                          end_time_ms, symbol_trades_vec)\n",
    "    sym_df = TradeDF(symbol_trades_vec)\n",
    "    sym_df.to_csv(\"periodicity_\" + str(symbol) + \"_\" + str(time.time()) +\".csv\", sep=',')\n",
    "    close_price_vector = sym_df['ExecPrice']\n",
    "\n",
    "    ps = np.abs(np.fft.fft(close_price_vector))**2\n",
    "    freqs = np.fft.fftfreq(len(close_price_vector), GLOBALS['BIN_INTERVAL_MS']/10**3)\n",
    "    if normalize_with_dc:\n",
    "        periodicity = np.max(ps[1:])/float(np.sum(ps))\n",
    "    else:\n",
    "        periodicity = np.max(ps[1:])/float(np.sum(ps[1:]))\n",
    "\n",
    "    print(symbol, periodicity)\n",
    "    return periodicity, freqs\n",
    "\n",
    "\n",
    "def multithreaded_volume_request(syms,seconds_in_past) : \n",
    "    import concurrent.futures\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [] \n",
    "        for sym in syms : \n",
    "            print(\"Submitting thread for sym: \" + sym )\n",
    "            future = executor.submit(aggregate_volume, sym, seconds_in_past)\n",
    "            futures.append(future)\n",
    "        \n",
    "    # now we get the results \n",
    "    values = [future.result() for future in futures ] \n",
    "    return values \n",
    "    \n",
    "def get_volume_for_symbol_in_thread(symbol, seconds_in_past) : \n",
    "    # create the thread \n",
    "    t = threading.Thread(target=aggregate_volume,\n",
    "                         args=(symbol,seconds_in_past))\n",
    "    # start the thread \n",
    "    t.start() \n",
    "    # return it \n",
    "    return t \n",
    "\n",
    "def ranked_volume_symbols(symbols , seconds_in_past) : \n",
    "    \n",
    "    ## -- \n",
    "    threads = [ get_volume_for_symbol_in_thread(symbol,seconds_in_past) for symbol in symbols  ] \n",
    "    \n",
    "    for thread in threads : \n",
    "        thread.join() \n",
    "    \n",
    "    ## -- \n",
    "\n",
    "def rank_symbols_by_volume(symbols , seconds_in_past) : \n",
    "    data = [ [symbol, aggregate_volume(symbol,seconds_in_past)  ] for  symbol in symbols ] \n",
    "    data.sort(key=lambda x:  x[1] , reverse=True )\n",
    "    return data\n",
    "\n",
    "def get_top_n_symbols_by_volume(symbols,seconds_in_past, n )  : \n",
    "    ranked = rank_symbols_by_volume(symbols,seconds_in_past) \n",
    "    syms = [ x[0] for x in ranked[0:n]] \n",
    "    return (syms , ranked)  \n",
    "\n",
    "def rank_symbols_by_periodicity(symbols , seconds_in_past) : \n",
    "    data = [ [symbol, periodicity_metric(symbol, seconds_in_past)  ] for  symbol in symbols ] \n",
    "    data.sort(key=lambda x:  x[1][0], reverse=True )\n",
    "    return data\n",
    "\n",
    "def get_top_n_symbols_by_periodicity(symbols,seconds_in_past, n )  : \n",
    "    ranked = rank_symbols_by_periodicity(symbols, seconds_in_past) \n",
    "    syms = [ x[0] for x in ranked[0:n]] \n",
    "    return (syms , ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_order(trader, symbol, price, num_shares, buy=True,limit=True):\n",
    "        \"\"\"\n",
    "        Place an order.\n",
    "\n",
    "        :param symbol: Symbol to buy or sell (str).\n",
    "        :param price: Price at which to execute the order (int).\n",
    "        :param num_shares: Number of shares to buy or sell (int).\n",
    "        :param buy: Whether to buy or sell (bool).\n",
    "        \"\"\"\n",
    "        returned_order_ = cloud_ex.Order()\n",
    "    \n",
    "        if limit : \n",
    "            type_ = cloud_ex.OrderType.limit \n",
    "        else : \n",
    "            type_ = cloud_ex.OrderType.market  \n",
    "\n",
    "        action_ = cloud_ex.OrderAction.buy if buy else cloud_ex.OrderAction.sell\n",
    "\n",
    "        # Submit order and wait\n",
    "        result = trader.SubmitOrder(symbol, returned_order_, type_,\n",
    "                                         action_, num_shares, int(price))\n",
    "        if result != cloud_ex.OrderResult.in_sequencer:\n",
    "            return None\n",
    "        return returned_order_.order_id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outstanding_orders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodicity_metric(\"CC\",60*18,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion from above is that multithreaded market data request is not helpful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_symbols, symbol_ranks = get_top_n_symbols_by_volume(default_symbols, 60*3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_volume('AD', 60*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_periodic, periodicity_ranks = get_top_n_symbols_by_periodicity(default_symbols, 24*60*60, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "periodicity_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getSymbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbol_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUERY ORDER HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Order Monitoring \n",
    "def outstanding_orders() : \n",
    "    outstanding_orders = cloud_ex.MapStringOrder()\n",
    "    trader.GetOutstandingOrders(outstanding_orders)\n",
    "    u.debug(\"You have {} outstanding orders.\".format(len(outstanding_orders)))\n",
    "    # Transform outstanding orders into a DataFrame\n",
    "    outstanding_orders = OutstandingOrderDF(outstanding_orders)\n",
    "    return outstanding_orders\n",
    "    \n",
    "def historical_orders() : \n",
    "    my_historical_orders = cloud_ex.VectorOrder()\n",
    "    trader.GetAllHistoricalOrders(my_historical_orders)\n",
    "    u.debug(\"You have submitted a total of {} order(s).\".format(len(my_historical_orders))) \n",
    "    my_historical_orders_df = OrderDF(my_historical_orders)\n",
    "    return my_historical_orders_df\n",
    "\n",
    "def historical_trades() : \n",
    "    my_historical_trades = cloud_ex.VectorTrade()\n",
    "    trader.GetAllHistoricalTrades(my_historical_trades)\n",
    "    u.debug(\"You have made a total of {} trade(s).\".format(len(my_historical_trades)))\n",
    "    my_historical_trades_df = TradeDF(my_historical_trades)\n",
    "    return my_historical_trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outstanding_orders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_trades()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can backtest our trading algorithms to get them ready for live trading. In the following cells we will download historical data and evaluate how well a mean reversion trader would have done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBALS = { \n",
    "    'NUM_SHARES' :  100, \n",
    "    'BIN_INTERVAL_MS' : 500,  #interval to bin the data with \n",
    "    'WAIT_INTERVAL_SECONDS' : 0.5, \n",
    "    'BACKTEST_LOOKBACK_PERIOD_SECONDS' : 6*60  , #amount of historical data to backtest on \n",
    "    'MAX_NUM_ORDERS' : 2*60*2 , #how long the algo will trade for, in # of bins \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get our bank of strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on strategy and strategy parameters terminology\n",
    "\n",
    "A strategy is implemented with specific parameters. <b>The pair of the strategy and parameters will be called an \"algo\"</b>\n",
    "The backtest logic will take a dictionary of string keys (identifiers) to a tuple of (strategy , params). This dictionary will be called \"algo_bank\" \n",
    "\n",
    "For example => "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from periodic_trader_vin import PeriodicTraderStrategy\n",
    "algo_bank = {'periodic_trader': PeriodicTraderStrategy()}      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the trading threads \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVE_THREADS = [] # global handle on the currently deployed threads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_evaluate_algorithm(**kwargs) : \n",
    "    \"\"\"\n",
    "    Intended as target of new thread() \n",
    "    1. Launches the algo on the symbol and starts trading \n",
    "    2. should calculate ROI of the algo \n",
    "    4. Writes ROI and submitted order ids to disk \n",
    "    \"\"\"\n",
    "    name     = kwargs['name']\n",
    "    strategy = kwargs['strategy']  \n",
    "    strategy_parameters = kwargs['strategy_parameters'] \n",
    "    num_shares = kwargs['num_shares'] \n",
    "    max_num_orders = kwargs['max_num_orders'] \n",
    "    symbol   = kwargs['symbol']\n",
    "    trader   = kwargs['trader'] #reference to the 1 trader instance connnected to cloudX\n",
    "    print(\"RE: Running algo: {} - {}\".format(name,symbol))\n",
    "\n",
    "    # create the AlgorithmicTrader Object \n",
    "    algo = strategy(trader, [symbol], bin_interval_ms=GLOBALS['BIN_INTERVAL_MS']) \n",
    "    \n",
    "    # get and set id for this trader  (for logging purposes)\n",
    "    trader_id = name + \"_\" + str(time.time()).split(\".\")[0]\n",
    "\n",
    "    # start and finish trading\n",
    "    order_ids = algo.trade(symbol,num_shares,max_num_orders,GLOBALS['WAIT_INTERVAL_SECONDS'] ,trader_id=trader_id,**strategy_parameters)\n",
    "\n",
    "    # write the order ids to a log file \n",
    "    u.logfile(trader_id + \"_order_ids\", json.dumps(order_ids) )\n",
    "\n",
    "\n",
    "def run_algorithm_in_thread(kwargs) : \n",
    "    # create the thread \n",
    "    print(\"Running algo in thread: {} - {}\".format(kwargs['name'],kwargs['symbol']))\n",
    "    t = threading.Thread(target=run_and_evaluate_algorithm,\n",
    "                         kwargs=kwargs)\n",
    "    # start the thread \n",
    "    t.start() \n",
    "    # return it\n",
    "    return t\n",
    "\n",
    "def deploy_top_N_algorithms(trader, ranked_algos, N,  num_shares, max_num_orders) : \n",
    "    global ACTIVE_THREADS\n",
    "    sublist = ranked_algos[0:N] \n",
    "    print(\"Deploying algos: \")\n",
    "    print(sublist) \n",
    "\n",
    "    # potential fix for the multi-threading?? \n",
    "    active_symbols = [ x[1] for x in sublist ] \n",
    "    print(\"Setting trader active symbols to: {}\".format(json.dumps(active_symbols)))\n",
    "    trader.set_active_symbols( active_symbols )\n",
    "\n",
    "    ts = []\n",
    "    for to_deploy in sublist : \n",
    "        roi, symbol, algoname , _  =  to_deploy \n",
    "        strategy, strategy_parameters = algo_bank[algoname]  \n",
    "        \n",
    "        arguments = { \n",
    "            'name' : algoname, \n",
    "            'strategy' : strategy, \n",
    "            'strategy_parameters' : strategy_parameters, \n",
    "            'num_shares' : num_shares, \n",
    "            'max_num_orders' : max_num_orders,  \n",
    "            'symbol' : symbol , \n",
    "            'trader' : trader ,\n",
    "        }\n",
    "        ts.append(run_algorithm_in_thread(arguments))\n",
    "    ACTIVE_THREADS = ts \n",
    "    return ts \n",
    "\n",
    "\n",
    "def get_most_periodic(symbols):\n",
    "    ranked_symbols = rank_symbols_by_periodicity(symbols , GLOBALS['BACKTEST_LOOKBACK_PERIOD_SECONDS'])\n",
    "    ranked_list = []\n",
    "    for idx in range(len(ranked_symbols)):\n",
    "        ranked_list.append([ranked_symbol[idx][1], ranked_symbol[idx][0], 'periodic_trader', ['buy', 'sell']])\n",
    "\n",
    "    return ranked_list\n",
    "\n",
    "\n",
    "def trade_algorithmically(trader, algobank, symbols, N=5) : \n",
    "    from random import sample \n",
    "    while True : \n",
    "        sym_subset = sample(symbols, 25)\n",
    "        u.logfile(\"tradeloop\", \"\\nBacktesting on symbols =>\")\n",
    "        u.logfile(\"tradeloop\", \"\\n{}\\n\".format(json.dumps(sym_subset)))\n",
    "\n",
    "        u.logfile(\"tradeloop\", \"\\n{}, Doing backtest\".format(time.time()))\n",
    "        ranked = get_most_periodic(sym_subset)\n",
    "        \n",
    "        fname = \"backtest_results_{}\".format(time.time())\n",
    "        u.logfile(fname, json.dumps(ranked))\n",
    "        u.logfile(\"tradeloop\",\"backtest_results=>\")\n",
    "        u.logfile(\"tradeloop\", \"\\n{}\\n\".format(json.dumps(ranked[0:N])))\n",
    "        u.logfile(\"tradeloop\", \"\\n{}, Launching Trading\".format(time.time()))\n",
    "        \n",
    "        algo_threads = deploy_top_N_algorithms(trader, ranked, N, GLOBALS['NUM_SHARES'] , GLOBALS['MAX_NUM_ORDERS']) \n",
    "        for t in algo_threads : \n",
    "            t.join()\n",
    "    \n",
    "def stop_trading_threads() : \n",
    "        print(\"There were {} threads running\".format(len(threading.enumerate())))\n",
    "        import os \n",
    "        import time\n",
    "        os.environ['STOP_TRADING'] = \"TRUE\" \n",
    "        time.sleep(GLOBALS['WAIT_INTERVAL_SECONDS']+0.1)\n",
    "        print(\"There are now {} threads running\".format(len(threading.enumerate())))\n",
    "        os.environ['STOP_TRADING'] = \"FALSE\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trade_algorithmically(getTrader(), algo_bank, default_symbols, N=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
